{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad7659ba-0b99-494e-8f38-4a6fb55efb58",
   "metadata": {},
   "source": [
    "# Lab 4d: Let's start working on our Bag of Words (BoW) implementation\n",
    "Ultimately, we will build a system that can classify text as positive or negative in tone, called [sentiment analysis](https://en.wikipedia.org/wiki/Sentiment_analysis). The objective of `lab-4d` is to familiarize students with working with text documents and a simple [natural language processing (NLP)](https://en.wikipedia.org/wiki/Natural_language_processing) model such as the [bag of words model](https://en.wikipedia.org/wiki/Bag-of-words_model).\n",
    "\n",
    "* We'll use the [Cornell movie review v2.0 data set](http://www.cs.cornell.edu/people/pabo/movie-review-data) as our corpus. This data set was introduced and analyzed in [Pang/Lee ACL 2004](https://aclanthology.org/P04-1035/). It contains 1000 positive and 1000 negative movie reviews in free(ish) text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b7e2a4-ab90-4a70-ace1-f80993588cc7",
   "metadata": {},
   "source": [
    "## Setup\n",
    "We set up the computational environment by including [the `Include. jl` file](Include.jl) using [the `include(...)` method](https://docs.julialang.org/en/v1/base/base/#Base.include). The [`Include.jl` file](Include.jl) loads external packages and functions we will use in these examples. \n",
    "* For additional information on functions and types used in this example, see the [Julia programming language documentation](https://docs.julialang.org/en/v1/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba8b1e06-749a-437e-a1bf-0390f66c0f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"Include.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dea9a43-f542-48d1-921b-3f47590b9b3a",
   "metadata": {},
   "source": [
    "## Prerequisite \n",
    "Break up into teams of 2-3 people and take `5 min` to walk through all the files (starting with [`Include.jl` in the `root` directory](Include.jl) in `Lab-4d`. At the end of `5 min`, we'll do a class Q&A to ensure everyone understands the purpose of each file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17fe5c5-f7b2-4717-a69e-c9416b2a9395",
   "metadata": {},
   "source": [
    "## Task 1: Load the positive and negative movie review datasets\n",
    "In this task, we will load the positive and negative movie datasets from the review text files by parsing each movie file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c88f18dc-8b47-403a-8d5b-e7c4bd2b244e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_positive_review_files = readdir(_PATH_TO_POSITIVE_REVIEWS); # what is happening here?\n",
    "postive_review_documents = readfiles(list_of_positive_review_files, \n",
    "    base = _PATH_TO_POSITIVE_REVIEWS, delim = \" \");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e29929-c6b1-4d4a-b49c-0cb052435237",
   "metadata": {},
   "source": [
    "Next, do the same thing for the negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77617683-6017-43bd-92dc-4c1f581bf87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_negative_review_files = readdir(_PATH_TO_NEGATIVE_REVIEWS);\n",
    "negative_review_documents = readfiles(list_of_negative_review_files, \n",
    "    base = _PATH_TO_NEGATIVE_REVIEWS, delim = \" \");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce506b5-1493-422d-964d-09662fef1583",
   "metadata": {},
   "source": [
    "## Task 2: Let's build a movie review corpus model\n",
    "In this task, we create [a `MyMoviewReviewDocumentCorpusModel` instance](src/Types.jl) that holds information about the _entire collection_ of positive and negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da19b7d5-6b92-4991-bfae-01484d9f7a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = let\n",
    "    allmoviewreviews = Dict{Int64, MyMoviewReviewRecordModel}();\n",
    "    counter = 1;\n",
    "    \n",
    "    for (k,v) ∈ postive_review_documents\n",
    "        allmoviewreviews[counter] = v;\n",
    "        counter += 1\n",
    "    end\n",
    "\n",
    "    for (k,v) ∈ negative_review_documents\n",
    "        allmoviewreviews[counter] = v;\n",
    "        counter += 1\n",
    "    end\n",
    "\n",
    "    build(MyMoviewReviewDocumentCorpusModel, allmoviewreviews)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50662814-52c6-4a07-8670-b506b679acc7",
   "metadata": {},
   "source": [
    "#### What's in the corpus model?\n",
    "Let's check out what's in the corpus model. The `records::Dict{Int64, MyMoviewReviewRecordModel}` dictionary holds a list of records, i.e., [`MyMoviewReviewRecordModel` instances](src/Types.jl). The key of the `records` dictionary is a file index, while the value is the `MyMoviewReviewRecordModel` model instance.\n",
    "* __Hmmm__: Is there a better way to link the files to the corresponding record than using a file index? Let's think about implementing an updated version of the records dictionary. Whatb is involved here (simple fix)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdc820bf-a9d8-453e-8e69-c3c1e8b0b826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Int64, MyMoviewReviewRecordModel} with 2002 entries:\n",
       "  1144 => MyMoviewReviewRecordModel([\"the\", \"first\", \"species\", \"was\", \"a\", \"mo…\n",
       "  1175 => MyMoviewReviewRecordModel([\"five\", \"years\", \"after\", \"his\", \"director…\n",
       "  1953 => MyMoviewReviewRecordModel([\"the\", \"44\", \"caliber\", \"killer\", \"has\", \"…\n",
       "  719  => MyMoviewReviewRecordModel([\"good\", \"films\", \"are\", \"hard\", \"to\", \"fin…\n",
       "  1546 => MyMoviewReviewRecordModel([\"i'll\", \"bet\", \"right\", \"now\", \"you're\", \"…\n",
       "  1703 => MyMoviewReviewRecordModel([\"the\", \"swooping\", \"shots\", \"across\", \"dar…\n",
       "  1956 => MyMoviewReviewRecordModel([\"i\", \"think\", \"maybe\", \"it's\", \"time\", \"fo…\n",
       "  1028 => MyMoviewReviewRecordModel([\"mulholland\", \"drive\", \"did\", \"very\", \"wel…\n",
       "  699  => MyMoviewReviewRecordModel([\"through\", \"a\", \"spyglass\", \"i\", \"could\", …\n",
       "  831  => MyMoviewReviewRecordModel([\"i\", \"know\", \"that\", \"funnest\", \"isn't\", \"…\n",
       "  1299 => MyMoviewReviewRecordModel([\"it\", \"would\", \"be\", \"hard\", \"to\", \"choose…\n",
       "  1438 => MyMoviewReviewRecordModel([\"woof\", \"too\", \"bad\", \"that\", \"leap\", \"of\"…\n",
       "  1074 => MyMoviewReviewRecordModel([\"this\", \"is\", \"your\", \"definitive\", \"holly…\n",
       "  319  => MyMoviewReviewRecordModel([\"the\", \"happy\", \"bastard's\", \"30-second\", …\n",
       "  687  => MyMoviewReviewRecordModel([\"what\", \"do\", \"you\", \"get\", \"when\", \"you\",…\n",
       "  1812 => MyMoviewReviewRecordModel([\"it\", \"rocks-actually\", \"lots\", \"of\", \"roc…\n",
       "  1199 => MyMoviewReviewRecordModel([\"one\", \"of\", \"the\", \"first\", \"films\", \"of\"…\n",
       "  185  => MyMoviewReviewRecordModel([\"to\", \"paraphrase\", \"a\", \"song\", \"title\", …\n",
       "  823  => MyMoviewReviewRecordModel([\"hedwig\", \"and\", \"the\", \"angry\", \"inch\", \"…\n",
       "  1090 => MyMoviewReviewRecordModel([\"ex-universal\", \"soldier\", \"luc\", \"has\", \"…\n",
       "  420  => MyMoviewReviewRecordModel([\"kirk\", \"douglas\", \"is\", \"one\", \"of\", \"tho…\n",
       "  1370 => MyMoviewReviewRecordModel([\"ugh\", \"that\", \"about\", \"sums\", \"this\", \"m…\n",
       "  1437 => MyMoviewReviewRecordModel([\"upon\", \"first\", \"viewing\", \"of\", \"this\", …\n",
       "  1662 => MyMoviewReviewRecordModel([\"what\", \"do\", \"you\", \"get\", \"when\", \"you\",…\n",
       "  1991 => MyMoviewReviewRecordModel([\"one\", \"of\", \"my\", \"favorite\", \"songs\", \"b…\n",
       "  ⋮    => ⋮"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2fa84d-1bcd-4f61-a6cf-8ff5da83da42",
   "metadata": {},
   "source": [
    "We can access the vocabulary dictionary (the mapping between `token => index`) in the `vocabulary::Dict{String, Int64}` field of the `corpus::MyMoviewReviewDocumentCorpusModel` instance.\n",
    "* __Hmmmmm__: There seem to be strange characters in the tokens. We need to update our logic to build the token collection. Update the implementation of [the `_deepclean(...)` function](src/Factory.jl), which removes forbidden characters. Let's do this as a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b84381ad-c6bb-4411-986b-07625a8b4cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## look at the vocab - have strange chars?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8675c137-9816-4692-b280-3a636689e227",
   "metadata": {},
   "source": [
    "## Task 3: Rethink the hashing vector formulation\n",
    "In this task, we're going to do some next-gen foo with [the `hashing(...)` function](src/Compute.jl); however, we need to have an `<OOV>` token in our vocabulary to make this happen. \n",
    "* __Hmmmmm__: Can you confirm that we have an `<OOV>` token in the corpus, and if not, add it? Wait a minute, do you know if we already add this to the records?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86371d34-f10f-4a5d-814e-b14e9979aafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in a check for the <OOV> token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b464c5ca-73e8-4a84-b8ca-380170d88066",
   "metadata": {},
   "source": [
    "We want [a `hashing(...)` function](src/Compute.jl) implementation that doesn't wrap back on itself for indexes larger than `size,` while simultaneously handing the `0-based` error issue, i.e., the error that is generated when $i\\leftarrow\\texttt{mod}(\\text{h},\\text{size})$ for the case of $\\text{h} = \\text{size}$. Also, what happens if we get a new review that uses words we don't have in the vocabulary?\n",
    "* __Hmmmmmm__: Let's revisit the implementation of [the `hashing(...)` function](src/Compute.jl) and try to address each of these issues. What kind of test case could we write to make sure this is working as it should?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a2c66d2-440b-40e7-af1f-f00bdc2a27cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "599-element Vector{Int64}:\n",
       " 5\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 2\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " ⋮\n",
       " 1\n",
       " 3\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 3\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let\n",
    "    test_record = corpus.records[1]; # pick a record at random\n",
    "    vocabulary = test_record.vocabulary;\n",
    "    inverse = test_record.inverse;\n",
    "    words = test_record.fields;\n",
    "\n",
    "    # compute a fv -\n",
    "    fv = hashing(words, hash = vocabulary, size = (length(vocabulary) + 1))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67273ddd-0931-4f30-955c-05e56a317e99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.5",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
