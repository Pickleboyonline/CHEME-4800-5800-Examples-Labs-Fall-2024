{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51dba82a-3861-41d1-beed-db31ad8afd46",
   "metadata": {},
   "source": [
    "# Example: Loading and Analyzing the Sarcasm Dataset\n",
    "This example will familiarize students with working with unstructured text, particularly the generation of a vocabulary model and the tokenization of text, i.e., the conversion of sentences into a mathematical representation.\n",
    "\n",
    "### Learning tasks\n",
    "* __Task 1__: Load the public sarcasm dataset. In this task, we'll load a public dataset of headlines that have been curated as either sarcastic or not sarcastic.\n",
    "* __Task 2__: Tokenize the headline records. In this task, we'll use the corpus model, particularly the `tokens::Dict{String, Int64}` dictionary, to tokenize headlines in our dataset, i.e., convert a text representation into a numerical vector representation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69630fa3-1f48-4773-a08a-316ac749a680",
   "metadata": {},
   "source": [
    "## Setup\n",
    "We set up the computational environment by including [the `Include. jl` file](Include.jl) using [the `include(...)` method](https://docs.julialang.org/en/v1/base/base/#Base.include). The [`Include.jl` file](Include.jl) loads external packages and functions we will use in these examples. \n",
    "* For additional information on functions and types used in this example, see the [Julia programming language documentation](https://docs.julialang.org/en/v1/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ee9ce5a-bcd7-4e5a-890e-7fd1dc43c799",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"Include.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316f88aa-17e9-492b-b7c1-63c57c930297",
   "metadata": {},
   "source": [
    "## Task 1: Load the public sarcasm dataset\n",
    "In this task, we'll load a public dataset of headlines that have been curated as either sarcastic or not sarcastic. The dataset we'll use is available on [Kaggle](https://www.kaggle.com/datasets/rmisra/news-headlines-dataset-for-sarcasm-detection) and is also discussed in the publications:\n",
    "1. Misra, Rishabh and Prahal Arora. \"Sarcasm Detection using News Headlines Dataset.\" AI Open (2023).\n",
    "2. Misra, Rishabh and Jigyasa Grover. \"Sculpting Data for ML: The first act of Machine Learning.\" ISBN 9798585463570 (2021).\n",
    "\n",
    "The data is encoded as a collection of `JSON` records (although it is not directly readable using a JSON parser). Each record has the following fields:\n",
    "* `is_sarcastic`: has a value of `1` if the record is sarcastic; otherwise, `0.`\n",
    "* `headline`: the headline of the article, unstructured text\n",
    "* `article_link`: link to the original news article. Useful in collecting supplementary data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f3e6f9-251b-44fc-805d-b8d67cf2aabe",
   "metadata": {},
   "source": [
    "We've developed a parser to read the sarcasm data file. The [`corpus(...)` method](src/Files.jl) takes the `path::String` argument (the path to the datafile) and returns a [`MySarcasmRecordCorpusModel` instance](src/Types.jl) which holds the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "167d0489-7541-48a7-9d04-dbb0c651f142",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusmodel = joinpath(_PATH_TO_DATA, \"Sarcasm_Headlines_Dataset_v2.txt\") |> corpus;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b4c73e-d6e3-438a-bd0e-1551f2d1a8c5",
   "metadata": {},
   "source": [
    "The [`MySarcasmRecordCorpusModel` instance](src/Types.jl) has the fields that are populated when we read the file:\n",
    "* The `records::Dict{Int, MySarcasmRecordModel}` field holds the original records data as a dictionary, where the keys of the dictionary correspond to the headline index, and the values are [instances of the `MySarcasmRecordModel` type](src/Types.jl).\n",
    "* The `tokens::Dict{String, Int64}` field holds the vocabulary computed over the dataset as a dictionary, where the dictionary's keys are the words (called tokens) and the values of the index of the word. We assemble the `tokens` dictionary in alphabetical order. This is initially undefined.\n",
    "* The `inverse::Dict{Int64, String}` field is the inverse of the `tokens` dictionary, where the keys are the token indexes and the values are the tokens (words).\n",
    "\n",
    "### TODO: Fix the punctuation issue\n",
    "* __Hmmm__: In this implementation, we allow punctuation characters in the tokens. We need to update the code to fix this issue. We have `29663` tokens in the lecture example, but we have `38246` tokens here. Fix this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "06bf7bc3-38f6-40a0-9869-b7d552464255",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusmodel.tokens;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e16cd26-7e86-41f6-aaa0-730b18e3b1c0",
   "metadata": {},
   "source": [
    "Each [`MySarcasmRecordModel` instance](src/Types.jl) has the three fields in the original data records: an `issarcastic::Bool` field holding the label for this record, the `headline::String` field holding the headline and the `article::String` field holding a link to the original article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b93c527-3b77-4b11-8f47-01f62144aacf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"mother comes pretty close to using word 'streaming' correctly\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpusmodel.records[5].headline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1e58e3-e33b-45bb-8dab-1ef64d4b2679",
   "metadata": {},
   "source": [
    "## Task 2: Tokenize the headline records\n",
    "In this task, we'll use the corpus model, particularly the `tokens::Dict{String, Int64}` dictionary, to tokenize headlines in our dataset, i.e., convert a text representation into a numerical vector representation. \n",
    "\n",
    "To better understand how this works, let's first examine a single (random) record and tokenize it.  We'll select a random record from the `number_of_records::Int64` possible records [using the built-in `rand(...)` method](https://docs.julialang.org/en/v1/stdlib/Random/#Base.rand), and store it in the `random_test_record::MySarcasmRecordModel` variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9b8f587-b23d-43eb-89be-df739f0c8ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MySarcasmRecordModel(true, \"convention crowd really hoping bill clinton breaks tension with joke about how terrible he looks\", \"https://politics.theonion.com/convention-crowd-really-hoping-bill-clinton-breaks-tens-1819579065\")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_records = corpusmodel.records |> length; # what is going on here?\n",
    "random_test_record = rand(1:number_of_records) |> i -> corpusmodel.records[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4aaee86-09cf-4253-83df-6df46e1f571e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"convention crowd really hoping bill clinton breaks tension with joke about how terrible he looks\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_test_record.headline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0667ba-6841-4a6e-85da-015e6d901594",
   "metadata": {},
   "source": [
    "Next, let's call [the `tokenize(...)` method](src/Compute.jl), which takes the `headline::String` that we want to tokenize, and our vocabulary stored in the `tokens::Dict{String, Int64}` dictionary and returns a token vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5add6a7f-6849-425d-9340-31c2208d9263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15-element Vector{Int64}:\n",
       " 10083\n",
       " 10694\n",
       " 28518\n",
       " 18099\n",
       "  6432\n",
       "  9187\n",
       "  7221\n",
       " 34267\n",
       " 37613\n",
       " 19932\n",
       "  3616\n",
       " 18254\n",
       " 34292\n",
       " 17445\n",
       " 21618"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv = tokenize(random_test_record.headline, corpusmodel.tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdd2eb1-9f8c-464d-bb4f-3c7d5031e20c",
   "metadata": {},
   "source": [
    "### Hmmm. What happens if a token is not in the dataset?\n",
    "We have created the vocabulary in the `tokens::Dict{String, Int64}` dictionary by analyzing the entire dataset, but suppose we have new samples that aren't in the dataset; what happens then? We've added the `<OOV>` token to our dataset; let's see if that works. \n",
    "* Let's take the headline from the `random_test_record::MySarcasmRecordModel` instance and add something to the end, e.g., `#ilovemyroomba`. we should get the `<OOV>` token at the end of the token vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3321c265-e767-4723-a987-ab8167ec6315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = corpusmodel.tokens |> keys |> collect; # what?? We are getting keys (words) and turning into an array\n",
    "\"#ilovemyroomba\" âˆˆ words # fancy way of checking if item is in array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8918b00-6479-410a-8186-429ef1d3744a",
   "metadata": {},
   "source": [
    "Create a new headline by appending `#ilovemyroomba` to the old headline. String append operations in Julia use [the `*` method](https://docs.julialang.org/en/v1/manual/strings/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81eb8f62-cf9e-4565-a343-088ba17af624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"convention crowd really hoping bill clinton breaks tension with joke about how terrible he looks #ilovemyroomba\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test_headline = random_test_record.headline * \" \" * \"#ilovemyroomba\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23853f2-0d19-4991-bbb6-cbe54f22832e",
   "metadata": {},
   "source": [
    "Tokenize the `new_test_headline::String`, and let's see what happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8796d1dd-ea5e-4b59-8eb3-37c5b05a2b67",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "KeyError: key \"<OOV>\" not found",
     "output_type": "error",
     "traceback": [
      "KeyError: key \"<OOV>\" not found",
      "",
      "Stacktrace:",
      " [1] getindex",
      "   @ ./dict.jl:498 [inlined]",
      " [2] tokenize(s::String, tokens::Dict{String, Int64}; pad::Int64, padleft::Bool, delim::Char)",
      "   @ Main ~/Desktop/julia_work/CHEME-4800-5800-Examples-Fall-2024/discussion/week-4/D4b/src/Compute.jl:28",
      " [3] tokenize(s::String, tokens::Dict{String, Int64})",
      "   @ Main ~/Desktop/julia_work/CHEME-4800-5800-Examples-Fall-2024/discussion/week-4/D4b/src/Compute.jl:16",
      " [4] top-level scope",
      "   @ In[21]:1"
     ]
    }
   ],
   "source": [
    "tv = tokenize(new_test_headline, corpusmodel.tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25f46ef-5086-4915-b283-91760c9cdac0",
   "metadata": {},
   "source": [
    "### TODO: Fix the `<OOV>` token issue \n",
    "* __Hmmm__: That didn't work as expected! We should have added the `<OOV>` token at the end of the token sequence, but for some reason we can't find the `<OOV>` token. Fix this!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523b4fca-8ae8-4aa5-9467-2966d8459035",
   "metadata": {},
   "source": [
    "### Compute the maximum pad length\n",
    "Not every headline has the same length, but we want the token vectors to have the same size. Thus, we'll find the longest vectors in the dataset and pad the token vectors to that length. To do that, let's iterate through each headline, compute its size, and then save this length if it is longer than we've seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48bc335b-be7d-4c63-b8d8-25fea7aff46e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_pad_length = 0; # initialize: we have 0 length\n",
    "for i âˆˆ 1:number_of_records\n",
    "    test_record_length = tokenize(corpusmodel.records[i].headline, corpusmodel.tokens) |> length; # tokenize, and calc the number of tokens\n",
    "    if (test_record_length > max_pad_length)\n",
    "        max_pad_length = test_record_length; # we've found a new longest headline!\n",
    "    end\n",
    "end\n",
    "max_pad_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4b7ba5-4690-4671-9034-327b409eaf2d",
   "metadata": {},
   "source": [
    "### Compute the vector representation of all headline samples\n",
    "Finally, now that we have found the `max_pad_length::Int64`, we can tokenize all records using the `max_pad_length::Int64` value as the `pad` value in [the `tokenize(...)` method](src/Compute.jl). \n",
    "* We'll use `right-padding` and will store the tokenized records for each headline in the `token_record_dictionary::Dict{Int64, Array{Int64,1}}` dictionary, where the keys of this dictionary are the record indexes, and the values of the tokenized records (which are of type `Array{Int64,1}.`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1901fd12-572e-4fed-8268-fb836e2f0ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151-element Vector{Int64}:\n",
       " 34518\n",
       " 30554\n",
       " 36111\n",
       " 12532\n",
       "  9208\n",
       " 24906\n",
       " 17031\n",
       " 21668\n",
       "     0\n",
       "     0\n",
       "     0\n",
       "     0\n",
       "     0\n",
       "     â‹®\n",
       "     0\n",
       "     0\n",
       "     0\n",
       "     0\n",
       "     0\n",
       "     0\n",
       "     0\n",
       "     0\n",
       "     0\n",
       "     0\n",
       "     0\n",
       "     0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_record_dictionary = Dict{Int64, Array{Int64,1}}();\n",
    "for i âˆˆ 1:number_of_records\n",
    "    \n",
    "    v = tokenize(corpusmodel.records[i].headline, corpusmodel.tokens, \n",
    "            pad = max_pad_length); \n",
    "    token_record_dictionary[i] = v;\n",
    "end\n",
    "token_record_dictionary[1] # tokenized record 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede85064-05f5-495a-b3d8-665320d03c42",
   "metadata": {},
   "source": [
    "## Final: Save data to disk\n",
    "We did a bunch of stuff in this example, and we don't want to have to recompute the corpus, token dictionary, etc. So let's save it [in an HDF5 encoded binary file](https://en.wikipedia.org/wiki/Hierarchical_Data_Format). To start, specify a path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ed269d6-4f4f-4e30-a7c7-f9f472351d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_save_file = joinpath(_PATH_TO_DATA, \"L4a-SarcasmSamplesTokenizer-SavedData.jld2\"); # JLD2 package encodes data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033a917a-8f05-4049-8d63-3d40ad1d4185",
   "metadata": {},
   "source": [
    "We'll write data to disk as a `jld2` (binary) saved file using [the `save(...)` method exported by the FileIO.jl package](https://github.com/JuliaIO/FileIO.jl). This will save the data as a [Julia `Dict` type](https://docs.julialang.org/en/v1/base/collections/#Base.Dict). The save file is [an HDF5 encoded file format](https://en.wikipedia.org/wiki/Hierarchical_Data_Format), which is small (compressed), which is excellent! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca9fba63-0141-4187-95d1-907a91d4ace1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save(path_to_save_file, Dict(\"corpus\" => corpusmodel, \"number_of_records\" => number_of_records)); # encode, and write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd54263d-3c88-4c02-8a46-2f24fe273011",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.5",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
