{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71a60d01-30b1-4b36-8386-58c9dc2b30d5",
   "metadata": {},
   "source": [
    "# Lab 8d: Building a Linear Regression Sarchasm Classifier\n",
    "In this lab, students will create a two-class linear classifier to predict whether a news headline is sarcastic or not. We'll estimate the parameters of this classifier using the ordinary least squares with and without regularization.  \n",
    "\n",
    "### Learning objectives and tasks\n",
    "* __Prerequisites__: To save some time, we'll load the saved file from the `SarcasmSamplesTokenizer` example from `week-4` using [the `load(...)` method exported by the FileIO.jl package](https://github.com/JuliaIO/FileIO.jl). We'll then use this data in the subsequent calculations.\n",
    "* __Task 1__: Compute the expected value of the parameters $\\beta$ without regularization. In this task, we estimate the parameters of a linear regression model that maps the text token sequences to the headline labels without regularization.\n",
    "* __Task 2__: Compute the expected value of the parameters $\\beta$ with regularization. In this task, we'll explore the effect of regularization on our ability to classify news headlines as sarcastic or not sarcastic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be8704d-2ac8-412c-9692-c2936715dfb1",
   "metadata": {},
   "source": [
    "## Setup\n",
    "We set up the computational environment by including [the `Include. jl` file](Include.jl) using [the `include(...)` method](https://docs.julialang.org/en/v1/base/base/#Base.include). The [`Include.jl` file](Include.jl) loads external packages and functions we will use in these examples. \n",
    "* For additional information on functions and types used in this example, see the [Julia programming language documentation](https://docs.julialang.org/en/v1/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20aa1055-5a47-4b32-a5b8-c170ca2eaeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"Include.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb17c7f-8129-4a58-a66f-a2eecf80889d",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "To save some time, we'll load the saved file from the `SarcasmSamplesTokenizer` example using [the `load(...)` method exported by the FileIO.jl package](https://github.com/JuliaIO/FileIO.jl). To load the `jld2` (binary) saved file, we pass the path to the file we want to load the [`load(...)` function](https://github.com/JuliaIO/FileIO.jl). This call returns the data as a [Julia `Dict` type](https://docs.julialang.org/en/v1/base/collections/#Base.Dict). \n",
    "* Let's set the path to the save file in the `path_to_save_file::String` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c3a524a-28e0-4870-a682-ba4ea4a66c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_save_file = joinpath(_PATH_TO_DATA, \"L4a-SarcasmSamplesTokenizer-SavedData.jld2\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543b873c-e9f6-46b8-b2b1-7d83386a59d9",
   "metadata": {},
   "source": [
    "Then we load the `jld2` file using [the `load(...)` method](https://juliaio.github.io/FileIO.jl/stable/reference/#FileIO.load), where the contents of the file are stored in the `saved_data_dictionary::Dict{String, Any}` variable. \n",
    "* We saved the `corpusmodel::MySarcasmRecordCorpusModel` instance, which holds the other interesting data, e.g., the `tokendictionary.` Thus, we can get (most) of everything we need from the `corpusmodel.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b4e7e23-19d8-413d-b6a4-52356eadb58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_data_dictionary = load(path_to_save_file);\n",
    "\n",
    "# pull data from the saved_data_dictionary -\n",
    "corpusmodel = saved_data_dictionary[\"corpus\"];\n",
    "\n",
    "tokendictionary = corpusmodel.tokens;\n",
    "inversetokendictionary = corpusmodel.inverse;\n",
    "number_of_records = saved_data_dictionary[\"number_of_records\"];\n",
    "\n",
    "# compute some stuff need for later -\n",
    "number_of_tokens = tokendictionary |> length; # size of the token dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c5ffb45-fa4d-4d4f-a956-9d1874bc5d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MySarcasmRecordModel(true, \"dollhousing crisis set to worsen mean older brother says\", \"https://entertainment.theonion.com/doll-housing-crisis-set-to-worsen-mean-older-brother-s-1819569425\")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpusmodel.records[1703]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762729a1-f60a-46ee-9767-1230a8f32f3b",
   "metadata": {},
   "source": [
    "### Compute the maximum pad length\n",
    "Not every headline has the same length, but we want the token vectors to have the same size. Thus, we'll find the longest vectors in the dataset and pad the token vectors to that length. To do that, let's iterate through each headline, compute its size, and then save this length if it is longer than we've seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09477d3f-d9f3-43db-aae2-b2b9b2ef8a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_pad_length = 0; # initialize: we have 0 length\n",
    "for i ∈ 1:number_of_records\n",
    "    test_record_length = tokenize(corpusmodel.records[i].headline, corpusmodel.tokens) |> length; # tokenize, and calc the number of tokens\n",
    "    if (test_record_length > max_pad_length)\n",
    "        max_pad_length = test_record_length; # we've found a new longest headline!\n",
    "    end\n",
    "end\n",
    "max_pad_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d596823a-72d2-497d-b75c-228b7257523f",
   "metadata": {},
   "source": [
    "### Compute the vector representation of all headline samples\n",
    "Now that we have found the `max_pad_length::Int64`, we can tokenize all records using the `max_pad_length::Int64` value as the `pad` value in [the `tokenize(...)` method](src/Compute.jl). \n",
    "* We'll use `right-padding` and will store the tokenized records for each headline in the `token_record_dictionary::Dict{Int64, Array{Int64,1}}` dictionary, where the keys of this dictionary are the record indexes and the values of the tokenized records (which are of type `Array{Int64,1}.`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9134e13d-d8ee-4a79-a699-7deee0e7e5b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151-element Vector{Int64}:\n",
       "  7439\n",
       " 22069\n",
       " 26972\n",
       " 17722\n",
       " 29031\n",
       "  6091\n",
       " 14100\n",
       "  9853\n",
       " 23998\n",
       " 18652\n",
       " 11233\n",
       " 21294\n",
       "  9259\n",
       "     ⋮\n",
       "   913\n",
       "   913\n",
       "   913\n",
       "   913\n",
       "   913\n",
       "   913\n",
       "   913\n",
       "   913\n",
       "   913\n",
       "   913\n",
       "   913\n",
       "   913"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_record_dictionary = Dict{Int64, Array{Int64,1}}();\n",
    "for i ∈ 1:number_of_records\n",
    "    \n",
    "    v = tokenize(corpusmodel.records[i].headline, corpusmodel.tokens, \n",
    "            pad = max_pad_length); \n",
    "    token_record_dictionary[i] = v;\n",
    "end\n",
    "token_record_dictionary[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4defb923-0612-46a9-b81b-81d69ac6fcdd",
   "metadata": {},
   "source": [
    "### Compute the vector representation of all labels\n",
    "Finally, let's compute the label dictionary. We'll store the labels in the `label_record_dictionary::Dict{Int64, Int64}` dictionary, where the keys of this dictionary are the record indexes, and the values are the labels: `sarcastic = 1`, while `not sarcastic = -1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c519966d-ff21-4954-9a8f-a10ca152a4e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Int64, Int64} with 28619 entries:\n",
       "  24824 => -1\n",
       "  25754 => -1\n",
       "  11950 => 1\n",
       "  1703  => 1\n",
       "  12427 => -1\n",
       "  7685  => -1\n",
       "  18374 => 1\n",
       "  3406  => -1\n",
       "  23970 => 1\n",
       "  27640 => 1\n",
       "  28576 => 1\n",
       "  1090  => -1\n",
       "  2015  => 1\n",
       "  18139 => -1\n",
       "  17088 => -1\n",
       "  11280 => 1\n",
       "  16805 => -1\n",
       "  28165 => 1\n",
       "  3220  => 1\n",
       "  11251 => -1\n",
       "  422   => 1\n",
       "  15370 => 1\n",
       "  25327 => -1\n",
       "  15859 => 1\n",
       "  4030  => 1\n",
       "  ⋮     => ⋮"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_record_dictionary = Dict{Int64, Int64}();\n",
    "for i ∈ 1:number_of_records\n",
    "    label = corpusmodel.records[i].issarcastic;\n",
    "    if (label == true)\n",
    "        label_record_dictionary[i] = 1;\n",
    "    else\n",
    "        label_record_dictionary[i] = -1;\n",
    "    end\n",
    "end\n",
    "label_record_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e39c7df-d048-4d56-9cf8-66f00277b163",
   "metadata": {},
   "source": [
    "### Partition the data matrix $\\mathbf{X}$ and the output $\\mathbf{Y}$\n",
    "We can now put the token vectors and the labels into a data matrix $\\mathbf{X}$ and an output vector $\\mathbf{Y}$.\n",
    "* The data matrix $\\mathbf{X}$ will be a `number_of_records` $\\times$ `max_pad_length` array holding `Int64` values (the token indexes). On the other hand, the output (label) vector will be a `number_of_records`$\\times$`1` column vector, holding the label for each record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc6955dc-5193-4758-97c8-112c80b7a7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = let\n",
    "\n",
    "    X = Array{Int64,2}(undef, number_of_records, max_pad_length);\n",
    "    Y = Array{Int64,1}(undef, number_of_records);\n",
    "    \n",
    "    for i ∈ 1:number_of_records\n",
    "        Y[i] = label_record_dictionary[i]; # get the label (output value)\n",
    "\n",
    "        tokens = token_record_dictionary[i];\n",
    "        for j ∈ 1:max_pad_length\n",
    "            X[i,j] = tokens[j];\n",
    "        end\n",
    "    end\n",
    "    X,Y\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a983a27-0fa5-4cbf-ac20-62060d88f6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28619×151 Matrix{Int64}:\n",
       " 26617  23295  27980   8295   5553  …  913  913  913  913  913  913  913\n",
       "  7439  22069  26972  17722  29031     913  913  913  913  913  913  913\n",
       "  8743  29545  28233    869   7418     913  913  913  913  913  913  913\n",
       " 13505  28804  20665  15447  10890     913  913  913  913  913  913  913\n",
       " 17429   5812  20655   5563  26826     913  913  913  913  913  913  913\n",
       " 17677  28994  13711    913    913  …  913  913  913  913  913  913  913\n",
       "   660  28770  26826  10197  29545     913  913  913  913  913  913  913\n",
       " 22445   3878  11455   8271  17853     913  913  913  913  913  913  913\n",
       " 23784  11625  11322  26902  15138     913  913  913  913  913  913  913\n",
       " 15835  18533  19309  14883  26618     913  913  913  913  913  913  913\n",
       " 26618  15393  14100   6145    914  …  913  913  913  913  913  913  913\n",
       "  1632  19544  26866  12555   7119     913  913  913  913  913  913  913\n",
       " 28939  26826  14883  21835   6904     913  913  913  913  913  913  913\n",
       "     ⋮                              ⋱         ⋮                        ⋮\n",
       " 28939  18886  11797   9873  17877     913  913  913  913  913  913  913\n",
       " 25320   5700   2370  26826  15617     913  913  913  913  913  913  913\n",
       "  2676  19083  28525  26826  25423     913  913  913  913  913  913  913\n",
       "  6094  19837  15161  10603   5864  …  913  913  913  913  913  913  913\n",
       " 11689   8201   4633  10603  17975     913  913  913  913  913  913  913\n",
       " 20189  21443  27678  10269  10603     913  913  913  913  913  913  913\n",
       " 13035  23054   1929   8250   7342     913  913  913  913  913  913  913\n",
       " 14350  26826   4870  22753  12305     913  913  913  913  913  913  913\n",
       " 13917   1258  14022   7921   6158  …  913  913  913  913  913  913  913\n",
       " 26534  17420   2971   1007  24917     913  913  913  913  913  913  913\n",
       " 16350  20752   7660   4362  18785     913  913  913  913  913  913  913\n",
       "  6990   5432  26618  18271    914     913  913  913  913  913  913  913"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0ad921-607e-4a3c-b696-709ec8a9fe35",
   "metadata": {},
   "source": [
    "Finally, let's partition the data into a `training` and `testing` set so that we can determine how well the model can predict unseen data, i.e., how well the model `generalizes.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38447f96-f179-4825-b475-293b2b5472bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction = 0.80\n",
    "(X_train, X_test, y_train, y_test) = partition(X, Y; trainfraction = fraction); # this is a *random* split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd086cef-52f0-443f-89dd-1b83fcc45644",
   "metadata": {},
   "source": [
    "## Task 1: Compute the expected value of the parameters $\\beta$ without regularization\n",
    "In this task, we estimate the parameters of a linear regression model that maps the text token sequences to the headline labels. \n",
    "We know that the `data matrix` $\\mathbf{X}$ is `overdetermined,` i.e., $m>n$ (more equations than unknowns). Thus, we are solving the minimization problem for an unknown parameter estimates $\\hat{\\beta}$:\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\hat{\\mathbf{\\beta}} = \\arg\\min_{\\mathbf{\\beta}} ||~\\mathbf{y} - \\mathbf{X}\\cdot\\mathbf{\\beta}~||^{2}_{2}\n",
    "\\end{equation*}\n",
    "$$\n",
    "where $||\\star||^{2}_{2}$ is the square of the p = 2 vector norm. Then, the value of the unknown parameter vector $\\mathbf{\\beta}$ that minimizes the sum of the squares loss function for an overdetermined system is given by:\n",
    "\\begin{equation*}\n",
    "\\hat{\\mathbf{\\beta}} = \\left(\\mathbf{X}^{T}\\mathbf{X}\\right)^{-1}\\mathbf{X}^{T}\\mathbf{y} - \\left(\\mathbf{X}^{T}\\mathbf{X}\\right)^{-1}\\mathbf{X}^{T}\\mathbf{\\epsilon}\n",
    "\\end{equation*}\n",
    "The matrix $\\mathbf{X}^{T}\\mathbf{X}$ is called the normal matrix, while $\\mathbf{X}^{T}\\mathbf{y}$ is called the moment matrix. The __expectation__ removes the error term."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb61ce4-861c-4f19-8dfa-06498b3121dc",
   "metadata": {},
   "source": [
    "### Check: Does the inverse of the normal matrix exist?\n",
    "Before we estimate the model parameters $\\hat{\\beta}$, let's check if the normal matrix $\\mathbf{X}^{T}\\mathbf{X}$ is invertible by calling [the `rank(...)` function exported by LinearAlgebra.jl](https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/#LinearAlgebra.rank).\n",
    "* If the normal matrix $\\mathbf{X}^{T}\\mathbf{X}$ has full rank, we can continue. However, if it does not, we must consider an alternative approach. Do this test [using the @assert macro](https://docs.julialang.org/en/v1/base/base/#Base.@assert)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59ac71fa-1cd8-4603-bf78-2ca819e155f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "AssertionError: rank(normal_matrix) == max_pad_length",
     "output_type": "error",
     "traceback": [
      "AssertionError: rank(normal_matrix) == max_pad_length",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[22]:2"
     ]
    }
   ],
   "source": [
    "normal_matrix = transpose(X)*X;\n",
    "@assert rank(normal_matrix) == max_pad_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84d59c0e-f4f6-49bf-9808-7bc4de1d7663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank(normal_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8e8fd4-6898-4d3a-8f5e-572df6f8b3a7",
   "metadata": {},
   "source": [
    "### Singular Value Decomposition\n",
    "Alternatively, we can compute the expected value of the parameters using  [singular value decomposition (SVD)](https://en.wikipedia.org/wiki/Singular_value_decomposition). Let the [singular value decomposition (SVD)](https://en.wikipedia.org/wiki/Singular_value_decomposition) of the $n\\times{p}$ data matrix $\\mathbf{X}$ be given by:\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\mathbf{X} = \\mathbf{U}\\cdot\\mathbf{\\Sigma}\\cdot\\mathbf{V}^{T}\n",
    "\\end{equation}\n",
    "$$\n",
    "where $\\mathbf{U}$ is an orthogonal matrix, $\\mathbf{\\Sigma}$ is a diagonal singular value matrix,\n",
    "and $\\mathbf{V}$ is an orthogonal matrix. Then, the regularized least-squares estimate of the unknown parameter vector $\\mathbf{\\theta}$ is given by:\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\hat{\\mathbf{\\theta}}_{\\lambda} = \\Bigl[\\left(\\mathbf{\\Sigma}^{T}\\mathbf{\\Sigma}+\\lambda\\mathbf{I}\\right)\\mathbf{V}^{T}\\Bigr]^{-1}\\cdot\\mathbf{\\Sigma^{T}}\\cdot\\mathbf{U}^{T}\\cdot\\mathbf{y}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13c174a5-76b2-442c-8f1a-65e99555fa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "β̂ = let\n",
    "    \n",
    "    (U,d,V) = svd(X_train);\n",
    "    Σ = diagm(d);\n",
    "    IM = diagm(ones(max_pad_length)); # we have max_pad_length parameters -\n",
    "\n",
    "    # compute θ̂ -\n",
    "    M = (transpose(Σ)*Σ)*transpose(V);\n",
    "    β̂ = inv(M)*transpose(Σ)*transpose(U)*y_train;\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f83bb7e-1e6f-472f-8a24-d3b16499c1e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151-element Vector{Float64}:\n",
       " -5.979431262515895e-6\n",
       " -5.009852616523295e-6\n",
       " -7.893868070784946e-7\n",
       " -1.546712165802769e-6\n",
       "  1.2762599944271766e-6\n",
       "  5.11944092458664e-7\n",
       " -8.371685470611177e-7\n",
       " -2.2512742425316202e-6\n",
       " -4.1930957053071245e-6\n",
       " -3.363373975143552e-6\n",
       " -1.5167025758792517e-6\n",
       "  2.4082065018479493e-6\n",
       "  4.514541972480354e-6\n",
       "  ⋮\n",
       "  7.301033649392176e8\n",
       "  1.3399418400210327e8\n",
       " -1.3383912294073488e8\n",
       "  1.1165973167040663e9\n",
       "  8.313695944187621e8\n",
       " -2.0463328575975308e9\n",
       "  6.1523323581464484e7\n",
       "  4.608048267622575e9\n",
       " -1.1311033462695882e9\n",
       " -3.378216399207363e9\n",
       " -2.1199616323590531e9\n",
       "  4.1877221061495266e9"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "β̂"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c771a4c5-166e-4a27-a4c6-92341037d802",
   "metadata": {},
   "source": [
    "### Compute the fraction correctly classified\n",
    "The parameters $\\hat{\\beta}$ can now be used to compute what the model says the labels should be, i.e., whether a story is sarcastic or not. Let's calculate the `y_model_train::Array{Float64,1}` array, which holds the model estimated labels for the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7576cc9d-2ca1-4240-b8b2-4c3a33a4551d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22896-element Vector{Float64}:\n",
       "  0.0712890625\n",
       " -0.0771484375\n",
       " -0.2021484375\n",
       "  0.1181640625\n",
       " -0.1240234375\n",
       "  0.0009765625\n",
       " -0.1240234375\n",
       "  0.0791015625\n",
       " -0.0380859375\n",
       " -0.2490234375\n",
       " -0.0537109375\n",
       " -0.1240234375\n",
       "  0.0166015625\n",
       "  ⋮\n",
       " -0.1318359375\n",
       " -0.1787109375\n",
       " -0.0693359375\n",
       " -0.0849609375\n",
       " -0.2333984375\n",
       " -0.0693359375\n",
       " -0.2255859375\n",
       " -0.4599609375\n",
       " -0.0849609375\n",
       " -0.1083984375\n",
       " -0.2412109375\n",
       "  0.0244140625"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_model_train = X_train*β̂"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69296c7-a70d-4cd7-8b37-213c46be0101",
   "metadata": {},
   "source": [
    "Hmmmm. If a bunch of floating point values. Let's propose a mapping between these values and the sarcasm labels:\n",
    "* if $\\hat{y}_{i}\\leq{0}$: the news headline is __not sarcastic__. Otherwise, for $\\hat{y}_{i}>0$ we classify the news headline as sarcastic.\n",
    "\n",
    "Let's implement this idea and compute the fraction of correctly labeled headlines for the training and testing datasets. We store the fraction of correct labels for the training data in the `f_train::Float64` variable and the fraction of correct labels for the testing data in the `f_test::Float64` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56c78156-583e-4d32-8002-ccad14093f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.12447589098532495, 0.12196400489253888)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_train, f_test = let\n",
    "\n",
    "    # compute what the model says the labels should be\n",
    "    y_model_train = X_train*β̂;\n",
    "    y_model_test = X_test*β̂;\n",
    "    number_of_training_samples = length(y_model_train);\n",
    "    number_of_testing_samples = length(y_model_test);\n",
    "    f_train = 0.0;\n",
    "    f_test = 0.0;\n",
    "\n",
    "    # -- TRAINING --------------------------------------------- #\n",
    "    N₊ = 0;\n",
    "    for i ∈ 1:number_of_training_samples\n",
    "        \n",
    "        label = 1; # default sarcasm\n",
    "        if (y_model_train[i] ≤ 0)\n",
    "            label = 0;\n",
    "        end\n",
    "        \n",
    "        if (label == y_train[i])\n",
    "           N₊ += 1;\n",
    "        end\n",
    "    end\n",
    "    f_train = N₊/number_of_training_samples;\n",
    "    # --------------------------------------------------------- #\n",
    "\n",
    "    # -- TESTING ---------------------------------------------- #\n",
    "    N₊ = 0;\n",
    "    for i ∈ 1:number_of_testing_samples\n",
    "        \n",
    "        label = 1; # default sarcasm\n",
    "        if (y_model_test[i] ≤ 0)\n",
    "            label = 0;\n",
    "        end\n",
    "        \n",
    "        if (label == y_test[i])\n",
    "           N₊ += 1;\n",
    "        end\n",
    "    end\n",
    "    f_test = N₊/number_of_testing_samples;\n",
    "    # --------------------------------------------------------- #\n",
    "    \n",
    "    # return -\n",
    "    f_train, f_test\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff94e02-f313-402f-8a47-9d3b957e5728",
   "metadata": {},
   "source": [
    "## Task 2: Compute the expected value of the parameters $\\beta$ with regularization\n",
    "In this task, we'll explore the effect of regularization on our ability to classify news headlines as sarcastic or not sarcastic. \n",
    "Let's see what happens when we add a regularization parameter. If we use `ridge` regularization, i.e., we add a $||\\,\\beta\\,||_{2}^{2}$ term to the objective function:\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\hat{\\mathbf{\\beta}} = \\arg\\min_{\\mathbf{\\beta}} ||~\\mathbf{y} - \\mathbf{X}\\cdot\\mathbf{\\beta}~||^{2}_{2} + \\lambda\\cdot{||\\,\\beta\\,||_{2}^{2}}\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "where $\\lambda\\geq{0}$ is called a `regularization` parameter. This problem has an analytical solution of the form:\n",
    "\\begin{equation*}\n",
    "\\hat{\\mathbf{\\beta}} = \\left(\\mathbf{X}^{T}\\mathbf{X}+\\lambda\\cdot\\mathbf{I}\\right)^{-1}\\mathbf{X}^{T}\\mathbf{y} - \\left(\\mathbf{X}^{T}\\mathbf{X}+\\lambda\\cdot\\mathbf{I}\\right)^{-1}\\mathbf{X}^{T}\\mathbf{\\epsilon}\n",
    "\\end{equation*}\n",
    "The __expectation__ removes the error term. Let's set a value for the regularization parameter $\\lambda\\geq{0}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4545af14-3911-40ae-9e4c-e871f97c2953",
   "metadata": {},
   "outputs": [],
   "source": [
    "λ = 1000.0; # select a value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e09a2ad-59ee-4c38-ac32-4ce3d4ba7b75",
   "metadata": {},
   "source": [
    "### Check: Does regularization fix the rank issue?\n",
    "Before we estimate the model parameters $\\hat{\\beta}$, let's check if the regularized normal matrix $\\mathbf{X}^{T}\\mathbf{X}+\\lambda\\cdot\\mathbf{I}$ is invertible by calling [the `rank(...)` function exported by LinearAlgebra.jl](https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/#LinearAlgebra.rank).\n",
    "* If the regularized normal matrix $\\mathbf{X}^{T}\\mathbf{X}+\\lambda\\cdot\\mathbf{I}$ has full rank, we can continue. However, if it does not, we must consider an alternative approach. Do this test [using the @assert macro](https://docs.julialang.org/en/v1/base/base/#Base.@assert)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "48077e3e-e0ee-4cb1-a573-99171eaef922",
   "metadata": {},
   "outputs": [],
   "source": [
    "IM = diagm(ones(max_pad_length));\n",
    "regularized_normal_matrix = transpose(X_train)*X_train + λ*IM;\n",
    "@assert rank(regularized_normal_matrix) == max_pad_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "83d21cc4-ec19-4886-a972-ba1ade16e3ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank(regularized_normal_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3c5582-4690-4c9a-bbe8-50822e23cee3",
   "metadata": {},
   "source": [
    "Wow! That is cool. Let's compute the expected value of the regression parameters $\\hat{\\beta}$ by inverting the regularized normal matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4ea4d752-7c63-4728-abc2-7908b53c12c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "β̂_reg = let\n",
    "    M = transpose(X_train)*X_train + λ*IM;\n",
    "    β̂_reg = inv(M)*transpose(X_train)*y_train\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c2ed8fb3-d7ab-4df0-b371-a93e330cb550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151-element Vector{Float64}:\n",
       " -6.079946870350997e-6\n",
       " -5.063287631827516e-6\n",
       " -5.090723400394878e-7\n",
       " -1.5042030668059354e-6\n",
       "  9.197697476048473e-7\n",
       "  6.985492053037843e-7\n",
       " -1.7038279440626006e-6\n",
       " -1.6616174518430898e-6\n",
       " -4.1930761845328326e-6\n",
       " -3.058442545053979e-6\n",
       " -1.306543078222001e-6\n",
       "  2.567658749989378e-6\n",
       "  4.568327469707909e-6\n",
       "  ⋮\n",
       "  6.612042004775177e-6\n",
       "  7.470455870679335e-6\n",
       "  6.321413600237137e-6\n",
       "  5.240510467593743e-6\n",
       "  3.876337525862323e-6\n",
       "  2.446345367202376e-6\n",
       "  4.088733757239409e-6\n",
       "  3.2395676728338844e-6\n",
       "  3.077223540439507e-6\n",
       "  2.439404874998472e-6\n",
       "  3.1537661856547724e-6\n",
       "  4.160646963463285e-6"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "β̂_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58c6160-47de-4a3d-bf81-4e68df8d79f4",
   "metadata": {},
   "source": [
    "### Compute the fraction correctly classified for the regularized case\n",
    "The parameters $\\hat{\\beta}$ can now be used to compute what the model says the labels should be, i.e., whether a story is sarcastic or not. Let's calculate the `y_model_train::Array{Float64,1}` array, which holds the model estimated labels for the training data for the regularized parameters.\n",
    "* We store the fraction of correct labels for the training data in the `f_train_reg::Float64` variable and the fraction of correct labels for the testing data in the `f_test_reg::Float64` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3a3af22a-786e-45aa-af57-3491d22d496e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1611198462613557, 0.16197798357504806)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_train_reg, f_test_reg = let\n",
    "\n",
    "    # compute what the model says the labels should be\n",
    "    y_model_train = X_train*β̂_reg;\n",
    "    y_model_test = X_test*β̂_reg;\n",
    "    number_of_training_samples = length(y_model_train);\n",
    "    number_of_testing_samples = length(y_model_test);\n",
    "    f_train = 0.0;\n",
    "    f_test = 0.0;\n",
    "\n",
    "    # -- TRAINING --------------------------------------------- #\n",
    "    N₊ = 0;\n",
    "    for i ∈ 1:number_of_training_samples\n",
    "        \n",
    "        label = 1; # default sarcasm\n",
    "        if (y_model_train[i] ≤ 0)\n",
    "            label = 0;\n",
    "        end\n",
    "        \n",
    "        if (label == y_train[i])\n",
    "           N₊ += 1;\n",
    "        end\n",
    "    end\n",
    "    f_train = N₊/number_of_training_samples;\n",
    "    # --------------------------------------------------------- #\n",
    "\n",
    "    # -- TESTING ---------------------------------------------- #\n",
    "    N₊ = 0;\n",
    "    for i ∈ 1:number_of_testing_samples\n",
    "        \n",
    "        label = 1; # default sarcasm\n",
    "        if (y_model_test[i] ≤ 0)\n",
    "            label = 0;\n",
    "        end\n",
    "        \n",
    "        if (label == y_test[i])\n",
    "           N₊ += 1;\n",
    "        end\n",
    "    end\n",
    "    f_test = N₊/number_of_testing_samples;\n",
    "    # --------------------------------------------------------- #\n",
    "    \n",
    "    # return -\n",
    "    f_train, f_test\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118d83f4-2e29-4b04-83bb-2851bbf3a1b0",
   "metadata": {},
   "source": [
    "## Hmmm. Both of these approaches give lousy performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6243c4-9951-43c9-86b3-d4dedf6cf253",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.1",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
